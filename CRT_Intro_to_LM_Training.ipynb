{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-XXT-Fo9GKb"
      },
      "source": [
        "# CRT in AI Training Week: NLP\n",
        "## Hands-on Lab for NLP w/ Language Models\n",
        "\n",
        "Instructor: Dhairya Dalal\n",
        "\n",
        "For this exercise we'll be using the CLINC-150 intent dataset. This dataset contains about 150 intents related to the banking domain. Intents range from common banking activites like bill_pay and new_card to more conversational topics like do_you_have_pet and tell_joke. Additionally, there is an OOS (out of scope)label which consists of random utterances that not supported by the existing intents. The goal of OOS label is maps random utterances or things the bot can't support to a single label that bot can use to provide response like \"I don't know\" or \"I'm sorry, I can't answer that for you\". You can learn more about the dataset here: https://www.aclweb.org/anthology/D19-1131.pdf\n",
        "\n",
        "\n",
        "## Environment Setup and Data Loading\n",
        "Before we get started, run the cells below. The first cell will install NLP libraries we'll be using for the lab. Note this cell may take a few minutes to run. The next cell will load nltk into the environment. The last cell will load our toy dataset in the colab enviroment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVdKWB5NI5Aa",
        "outputId": "eb6125b5-1b0c-40b8-dd4e-3c3f5038622f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.28.0\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets >> NULL\n",
        "!pip install transformers==4.28.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS0kTgU7uENU",
        "outputId": "b467be1a-d737-4dc4-9405-bb76ee42c476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-06 14:31:07--  https://archive.ics.uci.edu/ml/machine-learning-databases/00570/clinc150_uci.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1053960 (1.0M) [application/x-httpd-php]\n",
            "Saving to: ‘clinc150_uci.zip’\n",
            "\n",
            "clinc150_uci.zip    100%[===================>]   1.00M  3.47MB/s    in 0.3s    \n",
            "\n",
            "2023-06-06 14:31:07 (3.47 MB/s) - ‘clinc150_uci.zip’ saved [1053960/1053960]\n",
            "\n",
            "Archive:  clinc150_uci.zip\n",
            "   creating: clinc150_uci/\n",
            "  inflating: clinc150_uci/data_small.json  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/clinc150_uci/\n",
            "  inflating: __MACOSX/clinc150_uci/._data_small.json  \n",
            "  inflating: clinc150_uci/meta.txt   \n",
            "  inflating: __MACOSX/clinc150_uci/._meta.txt  \n",
            "  inflating: clinc150_uci/LICENSE    \n",
            "  inflating: clinc150_uci/data_oos_plus.json  \n",
            "  inflating: __MACOSX/clinc150_uci/._data_oos_plus.json  \n",
            "  inflating: clinc150_uci/data_imbalanced.json  \n",
            "  inflating: __MACOSX/clinc150_uci/._data_imbalanced.json  \n",
            "  inflating: clinc150_uci/data_full.json  \n",
            "  inflating: __MACOSX/clinc150_uci/._data_full.json  \n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00570/clinc150_uci.zip\n",
        "! unzip clinc150_uci.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "B0Qi-chguIP7",
        "outputId": "cb666f92-246f-4873-a97c-8d76d78a7abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in data dict:  dict_keys(['oos_val', 'val', 'train', 'oos_test', 'test', 'oos_train'])\n",
            "Sample of train data\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[['what are the steps for setting up direct deposit for my paycheck',\n",
              "  'direct_deposit'],\n",
              " ['how is a direct deposit set up', 'direct_deposit']]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Run this cell to load the data into memory\n",
        "import json\n",
        "import pandas as pd\n",
        "data = json.load(open(\"clinc150_uci/data_imbalanced.json\", \"r\"))\n",
        "\n",
        "# Keys in data dict\n",
        "print(f\"Keys in data dict:  {data.keys()}\")\n",
        "\n",
        "# Sample of data in raw form\n",
        "print(\"Sample of train data\")\n",
        "display(data[\"train\"][:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fxycNF5uLhC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_oos = pd.DataFrame(data[\"oos_train\"], columns=[\"text\", \"label\"])\n",
        "train = pd.DataFrame(data[\"train\"], columns=[\"text\", \"label\"])\n",
        "train_oos = pd.DataFrame(data[\"oos_test\"], columns=[\"text\", \"label\"])\n",
        "train[\"split\"] = \"train\"\n",
        "train_oos[\"split\"] = \"train\"\n",
        "\n",
        "train, val = train_test_split(train, test_size=.1, random_state=1988)\n",
        "train_oos, val_oos = train_test_split(train_oos, test_size=.1, random_state=1988)\n",
        "\n",
        "val[\"split\"] = \"val\"\n",
        "val_oos[\"split\"] = \"val\"\n",
        "\n",
        "test_oos = pd.DataFrame(data[\"oos_test\"], columns=[\"text\", \"label\"])\n",
        "test = pd.DataFrame(data[\"test\"], columns=[\"text\", \"label\"])\n",
        "test_oos[\"split\"] = \"test\"\n",
        "test[\"split\"] = \"test\"\n",
        "\n",
        "# Combine all into a single dataframe\n",
        "combined_data = pd.concat([train, train_oos, val, val_oos, test, test_oos])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7PoV-oYlbnd9",
        "outputId": "32120a45-37e6-480e-f05a-54168c777927"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-543dd679-202a-4a88-a2a8-e14b6748878f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>engage whisper mode now</td>\n",
              "      <td>whisper_mode</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3457</th>\n",
              "      <td>what's the deal with my health care</td>\n",
              "      <td>insurance</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>what is delta's carry on policy</td>\n",
              "      <td>carry_on</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1447</th>\n",
              "      <td>if you could remind me about doing laundry i w...</td>\n",
              "      <td>todo_list_update</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>how do i get my check directly deposited</td>\n",
              "      <td>direct_deposit</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>find my wallet</td>\n",
              "      <td>oos</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>can you give me the gps location of harvey</td>\n",
              "      <td>oos</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>where's my buddy steve right this second</td>\n",
              "      <td>oos</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>locate jenny at her present position</td>\n",
              "      <td>oos</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>let me know where jim is right now</td>\n",
              "      <td>oos</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17025 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-543dd679-202a-4a88-a2a8-e14b6748878f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-543dd679-202a-4a88-a2a8-e14b6748878f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-543dd679-202a-4a88-a2a8-e14b6748878f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text             label  \\\n",
              "230                             engage whisper mode now      whisper_mode   \n",
              "3457                what's the deal with my health care         insurance   \n",
              "133                     what is delta's carry on policy          carry_on   \n",
              "1447  if you could remind me about doing laundry i w...  todo_list_update   \n",
              "34             how do i get my check directly deposited    direct_deposit   \n",
              "...                                                 ...               ...   \n",
              "995                                      find my wallet               oos   \n",
              "996          can you give me the gps location of harvey               oos   \n",
              "997            where's my buddy steve right this second               oos   \n",
              "998                locate jenny at her present position               oos   \n",
              "999                  let me know where jim is right now               oos   \n",
              "\n",
              "      split  \n",
              "230   train  \n",
              "3457  train  \n",
              "133   train  \n",
              "1447  train  \n",
              "34    train  \n",
              "...     ...  \n",
              "995    test  \n",
              "996    test  \n",
              "997    test  \n",
              "998    test  \n",
              "999    test  \n",
              "\n",
              "[17025 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQDxVmPYzrtq"
      },
      "source": [
        "# Simple ML Baseline Model using TFIDF Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb3bUfq9uM0Y"
      },
      "outputs": [],
      "source": [
        "# Simple TFIDF Model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Feel free to use the train and test dataframes below.\n",
        "train = combined_data.query(\"split == 'train' \")\n",
        "test = combined_data.query(\"split == 'test' \")\n",
        "\n",
        "\n",
        "# Fit input vectorizer\n",
        "tfidf = TfidfVectorizer(lowercase=True)\n",
        "tfidf.fit(combined_data[\"text\"])\n",
        "\n",
        "# Generate X,y inputs for model\n",
        "\n",
        "# Train features and labels\n",
        "X_train = tfidf.transform(train[\"text\"])\n",
        "y_train = train[\"label\"]\n",
        "\n",
        "# Test features and labels\n",
        "X_test = tfidf.transform(combined_data.query(\"split=='test'\")[\"text\"])\n",
        "y_test = combined_data.query(\"split=='test'\")[\"label\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X3_e1zGucmR",
        "outputId": "16e90aeb-7fab-40fe-f798-24592a9db9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           precision    recall  f1-score   support\n",
            "\n",
            "      accept_reservations       0.96      0.87      0.91        30\n",
            "          account_blocked       0.91      0.70      0.79        30\n",
            "                    alarm       0.97      0.97      0.97        30\n",
            "       application_status       0.89      0.80      0.84        30\n",
            "                      apr       0.87      0.90      0.89        30\n",
            "            are_you_a_bot       0.90      0.93      0.92        30\n",
            "                  balance       0.90      0.63      0.75        30\n",
            "             bill_balance       0.70      0.23      0.35        30\n",
            "                 bill_due       0.78      0.47      0.58        30\n",
            "              book_flight       0.93      0.87      0.90        30\n",
            "               book_hotel       0.97      0.97      0.97        30\n",
            "               calculator       0.86      0.40      0.55        30\n",
            "                 calendar       0.79      0.63      0.70        30\n",
            "          calendar_update       0.79      0.87      0.83        30\n",
            "                 calories       1.00      0.93      0.97        30\n",
            "                   cancel       0.49      0.83      0.62        30\n",
            "       cancel_reservation       0.91      1.00      0.95        30\n",
            "               car_rental       1.00      0.90      0.95        30\n",
            "            card_declined       0.96      0.87      0.91        30\n",
            "                 carry_on       1.00      0.87      0.93        30\n",
            "            change_accent       0.88      0.93      0.90        30\n",
            "           change_ai_name       0.68      0.77      0.72        30\n",
            "          change_language       0.88      0.70      0.78        30\n",
            "             change_speed       0.68      0.93      0.79        30\n",
            "         change_user_name       0.76      0.73      0.75        30\n",
            "            change_volume       1.00      0.73      0.85        30\n",
            "      confirm_reservation       0.96      0.90      0.93        30\n",
            "                cook_time       1.00      0.73      0.85        30\n",
            "             credit_limit       0.77      0.67      0.71        30\n",
            "      credit_limit_change       0.85      0.77      0.81        30\n",
            "             credit_score       0.78      0.93      0.85        30\n",
            "         current_location       0.71      0.90      0.79        30\n",
            "             damaged_card       0.89      0.57      0.69        30\n",
            "                     date       0.87      0.87      0.87        30\n",
            "               definition       0.96      0.80      0.87        30\n",
            "           direct_deposit       1.00      1.00      1.00        30\n",
            "               directions       0.96      0.87      0.91        30\n",
            "                 distance       0.89      0.53      0.67        30\n",
            "         do_you_have_pets       0.91      1.00      0.95        30\n",
            "            exchange_rate       0.90      0.87      0.88        30\n",
            "          expiration_date       0.89      0.83      0.86        30\n",
            "               find_phone       0.95      0.70      0.81        30\n",
            "            flight_status       0.88      0.93      0.90        30\n",
            "                flip_coin       1.00      0.97      0.98        30\n",
            "                food_last       1.00      0.57      0.72        30\n",
            "           freeze_account       0.76      0.87      0.81        30\n",
            "                 fun_fact       0.88      0.97      0.92        30\n",
            "                      gas       0.76      0.87      0.81        30\n",
            "                 gas_type       0.89      0.83      0.86        30\n",
            "                  goodbye       0.80      0.67      0.73        30\n",
            "                 greeting       0.85      0.97      0.91        30\n",
            "                 how_busy       0.85      0.73      0.79        30\n",
            "          how_old_are_you       0.93      0.83      0.88        30\n",
            "     improve_credit_score       0.86      0.63      0.73        30\n",
            "                   income       0.81      0.70      0.75        30\n",
            "  ingredient_substitution       1.00      0.93      0.97        30\n",
            "         ingredients_list       0.89      0.80      0.84        30\n",
            "                insurance       1.00      0.87      0.93        30\n",
            "         insurance_change       0.84      0.87      0.85        30\n",
            "            interest_rate       1.00      0.83      0.91        30\n",
            "       international_fees       1.00      0.90      0.95        30\n",
            "       international_visa       0.62      0.87      0.72        30\n",
            "               jump_start       0.94      1.00      0.97        30\n",
            "         last_maintenance       0.81      0.97      0.88        30\n",
            "             lost_luggage       0.91      0.97      0.94        30\n",
            "                make_call       0.74      0.87      0.80        30\n",
            "                    maybe       0.86      0.83      0.85        30\n",
            "          meal_suggestion       0.71      0.67      0.69        30\n",
            "          meaning_of_life       0.93      0.93      0.93        30\n",
            "   measurement_conversion       1.00      0.83      0.91        30\n",
            "         meeting_schedule       1.00      0.83      0.91        30\n",
            "              min_payment       0.90      0.90      0.90        30\n",
            "                      mpg       0.87      0.87      0.87        30\n",
            "                 new_card       0.95      0.60      0.73        30\n",
            "             next_holiday       0.88      0.77      0.82        30\n",
            "                next_song       0.88      0.97      0.92        30\n",
            "                       no       0.81      0.83      0.82        30\n",
            "           nutrition_info       1.00      1.00      1.00        30\n",
            "           oil_change_how       0.77      0.90      0.83        30\n",
            "          oil_change_when       0.78      0.83      0.81        30\n",
            "                      oos       0.72      0.98      0.83      1000\n",
            "                    order       0.76      0.53      0.63        30\n",
            "             order_checks       1.00      0.73      0.85        30\n",
            "             order_status       0.83      0.83      0.83        30\n",
            "                 pay_bill       0.88      0.70      0.78        30\n",
            "                   payday       0.83      0.50      0.62        30\n",
            "               pin_change       0.96      0.90      0.93        30\n",
            "               play_music       0.87      0.67      0.75        30\n",
            "                plug_type       0.96      0.87      0.91        30\n",
            "              pto_balance       0.92      0.73      0.81        30\n",
            "              pto_request       0.85      0.77      0.81        30\n",
            "       pto_request_status       0.79      0.87      0.83        30\n",
            "                 pto_used       0.83      0.83      0.83        30\n",
            "                   recipe       0.80      0.53      0.64        30\n",
            "           redeem_rewards       0.50      0.23      0.32        30\n",
            "                 reminder       0.86      0.63      0.73        30\n",
            "          reminder_update       0.89      0.80      0.84        30\n",
            "                   repeat       0.84      0.87      0.85        30\n",
            "replacement_card_duration       0.94      0.50      0.65        30\n",
            "             report_fraud       0.78      0.60      0.68        30\n",
            "         report_lost_card       0.82      0.77      0.79        30\n",
            "           reset_settings       0.94      1.00      0.97        30\n",
            "   restaurant_reservation       0.88      0.93      0.90        30\n",
            "       restaurant_reviews       0.84      0.53      0.65        30\n",
            "    restaurant_suggestion       1.00      0.50      0.67        30\n",
            "          rewards_balance       0.79      0.63      0.70        30\n",
            "                roll_dice       1.00      1.00      1.00        30\n",
            "            rollover_401k       0.93      0.93      0.93        30\n",
            "                  routing       1.00      1.00      1.00        30\n",
            "     schedule_maintenance       1.00      0.87      0.93        30\n",
            "         schedule_meeting       0.82      0.93      0.87        30\n",
            "           share_location       0.91      0.67      0.77        30\n",
            "            shopping_list       0.69      0.60      0.64        30\n",
            "     shopping_list_update       0.74      0.77      0.75        30\n",
            "               smart_home       0.85      0.93      0.89        30\n",
            "                 spelling       0.96      0.77      0.85        30\n",
            "         spending_history       0.92      0.37      0.52        30\n",
            "              sync_device       0.80      0.93      0.86        30\n",
            "                    taxes       0.96      0.90      0.93        30\n",
            "                tell_joke       0.97      1.00      0.98        30\n",
            "                     text       1.00      0.87      0.93        30\n",
            "                thank_you       0.79      0.87      0.83        30\n",
            "                     time       0.84      0.87      0.85        30\n",
            "                    timer       1.00      0.97      0.98        30\n",
            "                 timezone       0.87      0.90      0.89        30\n",
            "              tire_change       1.00      0.80      0.89        30\n",
            "            tire_pressure       0.88      1.00      0.94        30\n",
            "                todo_list       0.62      0.50      0.56        30\n",
            "         todo_list_update       0.67      0.67      0.67        30\n",
            "                  traffic       1.00      1.00      1.00        30\n",
            "             transactions       1.00      0.13      0.24        30\n",
            "                 transfer       1.00      0.67      0.80        30\n",
            "                translate       0.96      0.83      0.89        30\n",
            "             travel_alert       0.75      0.90      0.82        30\n",
            "      travel_notification       0.77      0.90      0.83        30\n",
            "        travel_suggestion       0.87      0.67      0.75        30\n",
            "                     uber       1.00      1.00      1.00        30\n",
            "          update_playlist       1.00      0.97      0.98        30\n",
            "                user_name       0.68      0.87      0.76        30\n",
            "                 vaccines       0.96      0.90      0.93        30\n",
            "                       w2       0.93      0.83      0.88        30\n",
            "                  weather       0.94      0.97      0.95        30\n",
            "    what_are_your_hobbies       0.93      0.87      0.90        30\n",
            "       what_can_i_ask_you       0.79      0.73      0.76        30\n",
            "        what_is_your_name       0.95      0.67      0.78        30\n",
            "                what_song       0.71      0.90      0.79        30\n",
            "       where_are_you_from       0.80      0.93      0.86        30\n",
            "             whisper_mode       1.00      1.00      1.00        30\n",
            "      who_do_you_work_for       0.87      0.67      0.75        30\n",
            "             who_made_you       0.79      0.63      0.70        30\n",
            "                      yes       0.75      0.60      0.67        30\n",
            "\n",
            "                 accuracy                           0.83      5500\n",
            "                macro avg       0.87      0.80      0.82      5500\n",
            "             weighted avg       0.85      0.83      0.83      5500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Model training\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model evaluation\n",
        "preds = model.predict(X_test)  # generate predictions\n",
        "\n",
        "print(classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTJTYcCPPNpn"
      },
      "source": [
        "## NLP w/ Transformer Language Models\n",
        "\n",
        "For this part of the lab, we will explore using neural language models. Modern language models (BERT, ERNIE, GPT, T5, etc) have been found to be very effective across a wide range of NLP tasks. These models are usually deep neural networds which have been pretrained on large text corpora (i.e. Wikipedia, Common Crawl, BooksCorpus, etc) and are able to learn about the various aspects of language (syntax, grammar, semantics, etc) which can be tranferred acroos various domains and NLP tasks. The Transformer architecture (https://jalammar.github.io/illustrated-transformer/) tends to be the backbone for most modern language models. We sort the transformer models into two categories: autoregressive models and autencoding models. Autoregressive models (e.g. GPT, XLNet) are pretrained on the next word prediction. Given a sequence (the cat sat on the [BLANK]), the model attempts to predict the likely next word the sequence. In contrast autoencoding models (BERT, T5, RoBERTa, ERNIE) are trained to reconstruct corrupted sequences. So a given sentence like the cat sat on the mat would be corrupted by masking a random set of words, e.g. the [MASK] sat on the [MASK], where model must predict the masked tokens. Unlike autoregressive pretraining, the model uses the context of the full input to understand its masked constituent parts.\n",
        "\n",
        "There are two ways to use to these models given an arbitrary task. The weights of the model can be frozen and the last hidden layer output of the model can be used as a set of fixed features. While the method is very quick, it is limited in its efficacy. The other ways is finetuning. Finetuning is the process of updating the pretrained weights in order to adapt the model to a new task and domain (e.g. sentiment classification). Since the model already has internalized its own understanding of language, grammar, and semantics, finetuning usually only takes 1-5 epochs of additional gradient updates to condition the model to support the new task.\n",
        "\n",
        "\n",
        "The `HuggingFace` library hosts implementations and trained weights for nearly all the cutting edge Transformer models and has a unified and easy to use API for finetuning these models. For the final part of the lab we'll walk through how to prepare data for finetuning and train a model for our sentiment task.\n",
        "\n",
        "We'll explore finetuning the DistilBERT (https://arxiv.org/abs/1910.01108) model for the last section. DistilBERT reduces the size of BERT model (fewer parameters and hidden layers) which allows for quicker finetuning while still retaining 90% of BERT's performance. For all other consideritions (input encoding, training, etc) DistilBERT is identical to BERT. We recommend for this section to change your runtime type to GPU as it will dramatically speed up training time. You may find you'll need to rerun earlier cells to ensure the dataset is reloaded into memory.\n",
        "\n",
        "### 4.1 Data Preparation\n",
        "\n",
        "DistilBERT expects wordpiece ids as input. Wordpiece is subword (https://huggingface.co/course/chapter6/6?fw=pt) tokenization algorithm learns a fixed set of token and partial token units which can be used to construct any word. The `AutoTokenizer` class from can be used to load the BERT wordpiece vocabulary and automatically enocde any text to a sequence of wordpiece ids. Let's explore this a bit further below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0ILV7xjMkTd",
        "outputId": "6520b59b-d245-430e-a39c-ab3e27057f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer output a dictionary: {'input_ids': [101, 1996, 4248, 2829, 4419, 5598, 2058, 1996, 13971, 3899, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "# Import Autokenizer method from transformers\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load DistilBert vocabulary using the .from_pretrained method\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Encoding a sentence\n",
        "sent = \"The quick brown fox jumped over the lazy dog.\"\n",
        "print(f\"Tokenizer output a dictionary: {tokenizer(sent)}\")\n",
        "\n",
        "# We can also decode ids to vocabulary\n",
        "#print(tokenizer.decode([101, 1996, 4248, 2829, 4419, 5598, 2058, 1996, 13971, 3899, 1012, 102]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZhEKh5NutGR"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit(combined_data[\"label\"])\n",
        "combined_data[\"encoded_label\"] = le.transform(combined_data[\"label\"])\n",
        "combined_data\n",
        "\n",
        "train = combined_data.query(\"split == 'train' \")\n",
        "val = combined_data.query(\"split == 'val' \")\n",
        "test = combined_data.query(\"split == 'test' \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "9En2inZmdPL5",
        "outputId": "19ecebce-95f7-4c5b-9582-8fa1a0f12c03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text             label  \\\n",
              "230                             engage whisper mode now      whisper_mode   \n",
              "3457                what's the deal with my health care         insurance   \n",
              "133                     what is delta's carry on policy          carry_on   \n",
              "1447  if you could remind me about doing laundry i w...  todo_list_update   \n",
              "34             how do i get my check directly deposited    direct_deposit   \n",
              "...                                                 ...               ...   \n",
              "829   find out what gentlemen are wearing to wedding...               oos   \n",
              "936                 how many keys does a xylophone have               oos   \n",
              "817   explain how small talk helps bind groups together               oos   \n",
              "565               what is the best way to kill microbes               oos   \n",
              "877   please answer the phone and put it on speaker ...               oos   \n",
              "\n",
              "      split  encoded_label  \n",
              "230   train            147  \n",
              "3457  train             57  \n",
              "133   train             19  \n",
              "1447  train            128  \n",
              "34    train             35  \n",
              "...     ...            ...  \n",
              "829   train             80  \n",
              "936   train             80  \n",
              "817   train             80  \n",
              "565   train             80  \n",
              "877   train             80  \n",
              "\n",
              "[10372 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba1c4159-903a-4480-bf28-808e8aebd563\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "      <th>encoded_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>engage whisper mode now</td>\n",
              "      <td>whisper_mode</td>\n",
              "      <td>train</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3457</th>\n",
              "      <td>what's the deal with my health care</td>\n",
              "      <td>insurance</td>\n",
              "      <td>train</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>what is delta's carry on policy</td>\n",
              "      <td>carry_on</td>\n",
              "      <td>train</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1447</th>\n",
              "      <td>if you could remind me about doing laundry i w...</td>\n",
              "      <td>todo_list_update</td>\n",
              "      <td>train</td>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>how do i get my check directly deposited</td>\n",
              "      <td>direct_deposit</td>\n",
              "      <td>train</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>find out what gentlemen are wearing to wedding...</td>\n",
              "      <td>oos</td>\n",
              "      <td>train</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>how many keys does a xylophone have</td>\n",
              "      <td>oos</td>\n",
              "      <td>train</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>explain how small talk helps bind groups together</td>\n",
              "      <td>oos</td>\n",
              "      <td>train</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>what is the best way to kill microbes</td>\n",
              "      <td>oos</td>\n",
              "      <td>train</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>please answer the phone and put it on speaker ...</td>\n",
              "      <td>oos</td>\n",
              "      <td>train</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10372 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba1c4159-903a-4480-bf28-808e8aebd563')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba1c4159-903a-4480-bf28-808e8aebd563 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba1c4159-903a-4480-bf28-808e8aebd563');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDdrhYraOPyI"
      },
      "source": [
        "Next we need to create a custom Pytorch Dataset class to store the the generated encodings for our train corpus. The code below creates a custom class and generates the datasets for the train, val, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7r4f1QFPTs6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "# Define Custom Class for DistilBert Inputs\n",
        "class HFDataset(Dataset):\n",
        "\n",
        "    def __init__(self, encodings: dict):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        e = {k: v[idx] for k,v in self.encodings.items()}\n",
        "        return e\n",
        "\n",
        "# Define Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "\n",
        "# Train Inputs\n",
        "train_encodings = tokenizer(\n",
        "    train[\"text\"].tolist(),\n",
        "    padding=True,           # pad all inputs to max length\n",
        "    max_length=128,         # Bert max is 512, we choose 128 due to compute limitations\n",
        "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
        "    truncation=True\n",
        ")\n",
        "train_encodings[\"labels\"] = torch.tensor(train[\"encoded_label\"].tolist())  # Update train inputs with labels\n",
        "train_dataset = HFDataset(train_encodings)\n",
        "\n",
        "# # Val Inputs\n",
        "val_encodings = tokenizer(\n",
        "    val[\"text\"].tolist(),\n",
        "    padding=True,           # pad all inputs to max length\n",
        "    max_length=128,         # Bert max is 512, we choose 128 due to compute limitations\n",
        "    return_tensors=\"pt\",     # Return format pytorch tensor\n",
        "    truncation=True\n",
        ")\n",
        "val_encodings[\"labels\"] = torch.tensor(val[\"encoded_label\"].tolist())  # Update train inputs with labels\n",
        "val_dataset = HFDataset(val_encodings)\n",
        "\n",
        "\n",
        "# Test Inputs\n",
        "test_encodings = tokenizer(\n",
        "    test[\"text\"].tolist(),\n",
        "    padding=True,           # pad all inputs to max length\n",
        "    max_length=128,         # Bert max is 512, we choose 128 due to compute limitations\n",
        "    return_tensors=\"pt\",     # Return format pytorch tensor\n",
        "    truncation=True\n",
        ")\n",
        "test_y = test[\"encoded_label\"].tolist()\n",
        "test_dataset = HFDataset(test_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "HSgptHZ6R6pP",
        "outputId": "e910e23b-ebed-40f6-b538-6a019455c400"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 8526, 7204, 5549, 2085,  102,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
              "         [ 101, 2054, 1005, 1055, 1996, 3066, 2007, 2026, 2740, 2729,  102,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " 'labels': tensor([147,  57])}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Lets take a look at whats in the train dataset\n",
        "display(train_dataset[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e64lCP54eQYU",
        "outputId": "3bedbf88-da82-40f1-9b84-28b3630966cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['whisper_mode'], dtype=object)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.inverse_transform([147])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnCQKzL5R5rz"
      },
      "source": [
        "## 4.2 Model Training\n",
        "HuggingFace makes it simple to finetune transformer models for any task. First we load the pretrained model. `AutoModelForSequenceClassification` is a generic class combines an language model encoder with a classification head. Next create a `TrainingArgs` object which contains the training configuration details. Finally we create a `Trainer` object which will handle all the requisite training steps (i.e. learning rate scheduling, gradient backprop, etc)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "38bac866ee1a4256b0a8ad01c38e10b4",
            "cfae8b58a99b4e5c9f0077e39480bd1e",
            "359e50803d674a33a62a8f2abed074fd",
            "5ccc0345a1ab49e5acba8a402e757176",
            "17dc211b13844917bc93b0871dd7a373",
            "8d9682bbcc4d403c8dde9e0b0e3b1cbf",
            "d0090c99912749bb853acd46c67fd296",
            "d24b7ce557154c96b75d978f58d04682",
            "86fe798a5e5e402b9938c2c49ae2799a",
            "05f53d355b634356a7350e1ecf9542b1",
            "1d4a08191c6d4e898216454ac0cc9c26"
          ]
        },
        "id": "58ewdFLVbv2U",
        "outputId": "12162924-5f22-46fd-b5f6-29e29f95d0a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38bac866ee1a4256b0a8ad01c38e10b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import Trainer,  TrainingArguments\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=151)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "2V18kWXZeo1J",
        "outputId": "d57537f6-23ae-4478-d709-1886c602915e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1625' max='1625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1625/1625 02:18, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.376100</td>\n",
              "      <td>1.622281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.749700</td>\n",
              "      <td>0.533945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.301500</td>\n",
              "      <td>0.295464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.121300</td>\n",
              "      <td>0.222921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>0.207084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1625, training_loss=0.9681735335129958, metrics={'train_runtime': 141.0913, 'train_samples_per_second': 367.563, 'train_steps_per_second': 11.517, 'total_flos': 443954004306120.0, 'train_loss': 0.9681735335129958, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=5,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    per_device_train_batch_size = 32,\n",
        "    per_device_eval_batch_size = 32,\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mgduDjnVbz1"
      },
      "source": [
        "Now that our model is trained, we can generate prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "0LSl84I8eCST",
        "outputId": "236ce3f9-1c9c-46b2-9c5f-4850b9b84bb7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[-3.268, -6.188, -4.957, ..., -3.521, -5.09 , -4.027],\n",
              "       [-3.617, -5.92 , -4.84 , ..., -3.479, -5.055, -3.824],\n",
              "       [-3.15 , -6.17 , -5.51 , ..., -3.959, -4.973, -3.664],\n",
              "       ...,\n",
              "       [-4.516, -4.586, -5.785, ..., -4.312, -4.527, -6.56 ],\n",
              "       [-4.848, -4.156, -4.633, ..., -3.262, -3.85 , -6.832],\n",
              "       [-4.61 , -3.871, -5.023, ..., -4.203, -3.969, -6.406]],\n",
              "      dtype=float16), label_ids=None, metrics={'test_runtime': 1.7243, 'test_samples_per_second': 3189.732, 'test_steps_per_second': 99.752})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds = trainer.predict(test_dataset)\n",
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g8A8XHsitDY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "5f1375f7-808f-4ddc-ff21-fb4d933f4f01"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2cd52fb147ac>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'le' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "preds = le.inverse_transform(np.argmax(preds.predictions, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tm3j-JTgNiy",
        "outputId": "f3b22a8e-be8b-4462-f61e-ab531ac5887b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.92        30\n",
            "           1       0.87      0.90      0.89        30\n",
            "           2       0.97      0.97      0.97        30\n",
            "           3       1.00      1.00      1.00        30\n",
            "           4       0.93      0.93      0.93        30\n",
            "           5       1.00      0.97      0.98        30\n",
            "           6       0.79      0.77      0.78        30\n",
            "           7       0.88      0.70      0.78        30\n",
            "           8       0.89      0.83      0.86        30\n",
            "           9       0.96      0.90      0.93        30\n",
            "          10       1.00      1.00      1.00        30\n",
            "          11       0.97      0.93      0.95        30\n",
            "          12       0.96      0.73      0.83        30\n",
            "          13       0.79      0.90      0.84        30\n",
            "          14       1.00      1.00      1.00        30\n",
            "          15       0.88      1.00      0.94        30\n",
            "          16       0.97      1.00      0.98        30\n",
            "          17       1.00      1.00      1.00        30\n",
            "          18       0.96      0.80      0.87        30\n",
            "          19       1.00      0.87      0.93        30\n",
            "          20       0.97      1.00      0.98        30\n",
            "          21       0.83      0.97      0.89        30\n",
            "          22       1.00      1.00      1.00        30\n",
            "          23       0.94      1.00      0.97        30\n",
            "          24       0.97      1.00      0.98        30\n",
            "          25       1.00      0.83      0.91        30\n",
            "          26       1.00      1.00      1.00        30\n",
            "          27       0.97      0.97      0.97        30\n",
            "          28       0.96      0.83      0.89        30\n",
            "          29       0.97      0.97      0.97        30\n",
            "          30       0.91      0.97      0.94        30\n",
            "          31       0.91      1.00      0.95        30\n",
            "          32       1.00      0.73      0.85        30\n",
            "          33       0.94      0.97      0.95        30\n",
            "          34       1.00      0.93      0.97        30\n",
            "          35       1.00      0.97      0.98        30\n",
            "          36       0.94      1.00      0.97        30\n",
            "          37       0.96      0.87      0.91        30\n",
            "          38       1.00      1.00      1.00        30\n",
            "          39       1.00      0.97      0.98        30\n",
            "          40       0.93      0.93      0.93        30\n",
            "          41       0.97      0.97      0.97        30\n",
            "          42       0.94      1.00      0.97        30\n",
            "          43       1.00      1.00      1.00        30\n",
            "          44       1.00      0.90      0.95        30\n",
            "          45       0.96      0.87      0.91        30\n",
            "          46       0.97      1.00      0.98        30\n",
            "          47       0.97      0.93      0.95        30\n",
            "          48       1.00      0.97      0.98        30\n",
            "          49       0.90      0.90      0.90        30\n",
            "          50       0.94      0.97      0.95        30\n",
            "          51       0.90      0.87      0.88        30\n",
            "          52       0.97      1.00      0.98        30\n",
            "          53       0.93      0.93      0.93        30\n",
            "          54       0.86      0.83      0.85        30\n",
            "          55       0.93      0.83      0.88        30\n",
            "          56       0.93      0.90      0.92        30\n",
            "          57       0.94      1.00      0.97        30\n",
            "          58       1.00      0.90      0.95        30\n",
            "          59       1.00      0.73      0.85        30\n",
            "          60       0.91      1.00      0.95        30\n",
            "          61       0.88      1.00      0.94        30\n",
            "          62       0.97      1.00      0.98        30\n",
            "          63       0.94      1.00      0.97        30\n",
            "          64       1.00      1.00      1.00        30\n",
            "          65       0.88      0.93      0.90        30\n",
            "          66       0.91      0.97      0.94        30\n",
            "          67       0.89      0.83      0.86        30\n",
            "          68       0.97      0.93      0.95        30\n",
            "          69       0.96      0.90      0.93        30\n",
            "          70       0.94      0.97      0.95        30\n",
            "          71       0.88      0.93      0.90        30\n",
            "          72       0.94      1.00      0.97        30\n",
            "          73       0.90      0.87      0.88        30\n",
            "          74       0.97      0.97      0.97        30\n",
            "          75       0.97      0.97      0.97        30\n",
            "          76       0.97      1.00      0.98        30\n",
            "          77       1.00      1.00      1.00        30\n",
            "          78       0.81      1.00      0.90        30\n",
            "          79       0.93      0.93      0.93        30\n",
            "          80       0.94      0.99      0.96      1000\n",
            "          81       0.76      0.83      0.79        30\n",
            "          82       0.88      1.00      0.94        30\n",
            "          83       0.87      0.90      0.89        30\n",
            "          84       0.93      0.90      0.92        30\n",
            "          85       0.97      0.93      0.95        30\n",
            "          86       1.00      0.80      0.89        30\n",
            "          87       0.90      0.90      0.90        30\n",
            "          88       1.00      0.93      0.97        30\n",
            "          89       0.78      0.97      0.87        30\n",
            "          90       0.96      0.90      0.93        30\n",
            "          91       0.90      0.90      0.90        30\n",
            "          92       0.96      0.87      0.91        30\n",
            "          93       0.90      0.93      0.92        30\n",
            "          94       0.90      0.87      0.88        30\n",
            "          95       0.93      0.93      0.93        30\n",
            "          96       0.96      0.87      0.91        30\n",
            "          97       1.00      0.90      0.95        30\n",
            "          98       0.89      0.83      0.86        30\n",
            "          99       0.95      0.63      0.76        30\n",
            "         100       0.84      0.90      0.87        30\n",
            "         101       1.00      1.00      1.00        30\n",
            "         102       0.85      0.93      0.89        30\n",
            "         103       1.00      0.90      0.95        30\n",
            "         104       0.96      0.87      0.91        30\n",
            "         105       0.87      0.90      0.89        30\n",
            "         106       1.00      1.00      1.00        30\n",
            "         107       1.00      1.00      1.00        30\n",
            "         108       1.00      1.00      1.00        30\n",
            "         109       1.00      0.93      0.97        30\n",
            "         110       0.94      1.00      0.97        30\n",
            "         111       0.93      0.90      0.92        30\n",
            "         112       0.88      0.70      0.78        30\n",
            "         113       0.91      0.97      0.94        30\n",
            "         114       0.97      0.97      0.97        30\n",
            "         115       1.00      0.97      0.98        30\n",
            "         116       0.81      0.87      0.84        30\n",
            "         117       1.00      0.97      0.98        30\n",
            "         118       1.00      0.97      0.98        30\n",
            "         119       1.00      1.00      1.00        30\n",
            "         120       0.96      0.90      0.93        30\n",
            "         121       0.90      0.93      0.92        30\n",
            "         122       0.96      0.90      0.93        30\n",
            "         123       1.00      0.97      0.98        30\n",
            "         124       1.00      0.97      0.98        30\n",
            "         125       1.00      0.97      0.98        30\n",
            "         126       0.97      1.00      0.98        30\n",
            "         127       0.88      0.97      0.92        30\n",
            "         128       0.97      0.97      0.97        30\n",
            "         129       1.00      1.00      1.00        30\n",
            "         130       0.85      0.73      0.79        30\n",
            "         131       0.93      0.90      0.92        30\n",
            "         132       0.86      1.00      0.92        30\n",
            "         133       0.97      1.00      0.98        30\n",
            "         134       0.90      0.93      0.92        30\n",
            "         135       0.97      0.93      0.95        30\n",
            "         136       0.97      1.00      0.98        30\n",
            "         137       1.00      0.97      0.98        30\n",
            "         138       1.00      0.97      0.98        30\n",
            "         139       1.00      1.00      1.00        30\n",
            "         140       0.97      1.00      0.98        30\n",
            "         141       0.94      1.00      0.97        30\n",
            "         142       1.00      0.93      0.97        30\n",
            "         143       0.91      1.00      0.95        30\n",
            "         144       0.90      0.93      0.92        30\n",
            "         145       0.97      0.97      0.97        30\n",
            "         146       1.00      0.97      0.98        30\n",
            "         147       0.91      1.00      0.95        30\n",
            "         148       0.96      0.80      0.87        30\n",
            "         149       0.91      1.00      0.95        30\n",
            "         150       1.00      0.80      0.89        30\n",
            "\n",
            "    accuracy                           0.94      5500\n",
            "   macro avg       0.94      0.93      0.94      5500\n",
            "weighted avg       0.94      0.94      0.94      5500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(le.inverse_transform(test_y), preds))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38bac866ee1a4256b0a8ad01c38e10b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfae8b58a99b4e5c9f0077e39480bd1e",
              "IPY_MODEL_359e50803d674a33a62a8f2abed074fd",
              "IPY_MODEL_5ccc0345a1ab49e5acba8a402e757176"
            ],
            "layout": "IPY_MODEL_17dc211b13844917bc93b0871dd7a373"
          }
        },
        "cfae8b58a99b4e5c9f0077e39480bd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d9682bbcc4d403c8dde9e0b0e3b1cbf",
            "placeholder": "​",
            "style": "IPY_MODEL_d0090c99912749bb853acd46c67fd296",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "359e50803d674a33a62a8f2abed074fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d24b7ce557154c96b75d978f58d04682",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86fe798a5e5e402b9938c2c49ae2799a",
            "value": 267967963
          }
        },
        "5ccc0345a1ab49e5acba8a402e757176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05f53d355b634356a7350e1ecf9542b1",
            "placeholder": "​",
            "style": "IPY_MODEL_1d4a08191c6d4e898216454ac0cc9c26",
            "value": " 268M/268M [00:02&lt;00:00, 101MB/s]"
          }
        },
        "17dc211b13844917bc93b0871dd7a373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9682bbcc4d403c8dde9e0b0e3b1cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0090c99912749bb853acd46c67fd296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d24b7ce557154c96b75d978f58d04682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86fe798a5e5e402b9938c2c49ae2799a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05f53d355b634356a7350e1ecf9542b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d4a08191c6d4e898216454ac0cc9c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}